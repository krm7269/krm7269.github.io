<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Senior Project Testing</title>
<style>
#container {
	align: left;
	width: 500px;
	height: 375px;
	border: 10px #333 solid;
}
#videoElement {
	width: 500px;
	height: 375px;
	background-color: #666;
}
#videoElementCV {
	width: 500px;
	height: 375px;
	background-color: #666;
}
#videoElementCV2 {
	width: 500px;
	height: 375px;
	background-color: #666;
}
button {
	margin-top: 20px;
	font-size: 12px;
	font-weight: bold;
	padding: 5px;
	background-color: white;
	border: 5px solid black;
}
button:hover {
	background-color: grey;
}
button:active {
	background-color: yellowgreen;
}
</style>
</head>
<body>
<h1>Senior Project Testing</h1>
<p>This is a testing website for me to mess with front end development and openCV.</p>
	
<!--.......................This is for the webcam block..................-->

<h2>Webcam Testing</h2>
<div id="container">
	<video autoplay="true" id="videoElement">
	</video>
</div>
<button id="stop">Stop Video</button> <button id="start">Start Video</button>
<script>
var video = document.querySelector("#videoElement");
var stopVideo = document.querySelector("#stop");
var startVideo = document.querySelector("#start");
stopVideo.addEventListener("click", stop, false);
startVideo.addEventListener("click", start, false);
function start(e) {
	if (navigator.mediaDevices.getUserMedia) {
		navigator.mediaDevices.getUserMedia({ video: true })
			.then(function (stream) {
				video.srcObject = stream;
			})
			.catch(function (err0r) {
				console.log("Something went wrong!");
			});
	}
}	
function stop(e) {
	if (video.srcObject != null) {
		var stream = video.srcObject;
		var tracks = stream.getTracks();

		for (var i = 0; i < tracks.length; i++) {
			var track = tracks[i];
			track.stop();
		}
		video.srcObject = null;
	}
}
</script>
	
<!--.......................This is for the OpenCV block..................-->
	
<h2>OpenCV.js Testing</h2>
<table cellpadding="0" cellspacing="0" width="0" height="0" border="0">
	<tbody><tr><td>
			<div id="container">
				<video autoplay="true" id="videoInput"></video>
			</div>
		</td>
		<td>
			<div id="container">
				<canvas id="canvasOutput"></canvas>
			</div>
	</td></tr></tbody>
</table>
<button id="startAndStop">Stop</button>
<p class="err" id="errorMessage"></p>
<script async type="text/javascript" src="opencv.js"></script>
<script src="utils.js" type="text/javascript"></script>
<script id="codeSnippet" type="text/code-snippet">
let video = document.getElementById('videoInput');
let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
let gray = new cv.Mat();
let cap = new cv.VideoCapture(video);
let faces = new cv.RectVector();
let classifier = new cv.CascadeClassifier();

// load pre-trained classifiers
classifier.load('haarcascade_frontalface_default.xml');

const FPS = 30;
function processVideo() {
    try {
        if (!streaming) {
            // clean and stop.
            src.delete();
            dst.delete();
            gray.delete();
            faces.delete();
            classifier.delete();
            return;
        }
        let begin = Date.now();
        // start processing.
        cap.read(src);
        src.copyTo(dst);
        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
        // detect faces.
        classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
        // draw faces.
        for (let i = 0; i < faces.size(); ++i) {
            let face = faces.get(i);
            let point1 = new cv.Point(face.x, face.y);
            let point2 = new cv.Point(face.x + face.width, face.y + face.height);
            cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
        }
        cv.imshow('canvasOutput', dst);
        // schedule the next one.
        let delay = 1000/FPS - (Date.now() - begin);
        setTimeout(processVideo, delay);
    } catch (err) {
        utils.printError(err);
    }
};

// schedule the first one.
setTimeout(processVideo, 0);
</script>
<script type="text/javascript">
let utils = new Utils('errorMessage');

utils.loadCode('codeSnippet', 'codeEditor');

let streaming = false;
let videoInput = document.getElementById('videoInput');
let startAndStop = document.getElementById('startAndStop');
let canvasOutput = document.getElementById('canvasOutput');
let canvasContext = canvasOutput.getContext('2d');

startAndStop.addEventListener('click', () => {
    if (!streaming) {
        utils.clearError();
        utils.startCamera('qvga', onVideoStarted, 'videoInput');
    } else {
        utils.stopCamera();
        onVideoStopped();
    }
});

function onVideoStarted() {
    streaming = true;
    startAndStop.innerText = 'Stop';
    videoInput.width = videoInput.videoWidth;
    videoInput.height = videoInput.videoHeight;
    utils.executeCode('codeEditor');
}

function onVideoStopped() {
    streaming = false;
    canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
    startAndStop.innerText = 'Start';
}

utils.loadOpenCv(() => {
    let faceCascadeFile = 'haarcascade_frontalface_default.xml';
    utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
        startAndStop.removeAttribute('disabled');
    });
});
</script>
</body>
</html>
